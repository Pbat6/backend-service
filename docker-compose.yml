services:
  postgres:
    image: postgres:15
    container_name: postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: admin
      POSTGRES_DB: backend-service
      PGDATA: /data/postgres
    volumes:
      - postgres:/data/postgres
    ports:
      - '5432:5432'
    networks:
      - backend

  redis:
    image: redis:6.2-alpine
    container_name: redis
    hostname: redis
    ports:
      - '6379:6379'
    environment:
      - ALLOW_EMPTY_PASSWORD=yes
      - REDIS_DISABLE_COMMANDS=FLUSHDB;FLUSHALL
    networks:
      - backend

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - '22181:2181'
    networks:
      - backend

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - '29092:29092'
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - backend

#  init-kafka-container:
#    image: confluentinc/cp-kafka:latest
#    depends_on:
#      - kafka
#    entrypoint: [ '/bin/sh', '-c' ]
#    command: >
#      # rather than giving sleep 15 use this
#      # to block init container to wait for Kafka broker to be ready
#      kafka-topics --bootstrap-server kafka:9092 --list
#
#      # create init topics
#      kafka-topics --create --partitions 3 --bootstrap-server kafka:9092 --topic input
#      kafka-topics --create --bootstrap-server kafka:9092 --partitions 1 --topic output

  backend-service:
    container_name: backend-service
    build:
      context: ./
      dockerfile: Dockerfile
    env_file:
      - .env
    ports:
      - '8080:8080'
    networks:
      - backend

  elastic-search:
    image: elasticsearch:7.14.1
    container_name: elasticsearch
    restart: always
    ports:
      - "9200:9200"
    environment:
      - discovery.type=single-node
    networks:
      - backend

  kibana:
    image: kibana:7.14.1
    container_name: kibana
    restart: always
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elastic-search:9200
    networks:
      - backend

  logstash:
    image: logstash:7.14.1
    container_name: logstash
    restart: always
    ports:
      - "5600:5600"
      - "5044:5044"
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    environment:
      - XPACK_MONITORING_ELASTICSEARCH_HOSTS=http://elastic-search:9200
      - XPACK_MONITORING_ENABLED=true
    networks:
      - backend

  prometheus:
    image: prom/prometheus
    container_name: prometheus
    restart: unless-stopped
    command:
      - --config.file=/etc/prometheus/prometheus.yml
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    networks:
      - backend

  grafana:
    image: grafana/grafana
    container_name: grafana
    restart: unless-stopped
    environment: # account: admin/admin
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    ports:
      - "3000:3000"
    links:
      - prometheus
    volumes:
      - grafana:/var/lib/grafana
    networks:
      - backend

networks:
  backend:
    driver: bridge

volumes:
  postgres:
  grafana: